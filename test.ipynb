{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import dgl\n",
    "    \n",
    "# # pandas reads csv\n",
    "# edges_data = pd.read_csv('data/knowledge_aquisition_reference.csv')\n",
    "# # networkx reads pandas\n",
    "# g_nx: nx.DiGraph = nx.from_pandas_edgelist(edges_data,\n",
    "#                                                'paper_id',\n",
    "#                                                'reference_id',\n",
    "#                                                create_using=nx.DiGraph())\n",
    "\n",
    "# # dgl read networkx\n",
    "# # ATTENTION!!!: nodes in dgl graph is ordered by paperid\n",
    "# g = dgl.from_networkx(g_nx)\n",
    "# print(g.number_of_nodes())\n",
    "# print(g.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl.function as fn\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "gcn_msg = fn.copy_src(src='h' ,out='m')\n",
    "gcn_reduce = fn.sum(msg='m' ,out='h')\n",
    "\n",
    "class GCNLayer(nn.Module):\n",
    "    def __init__(self, in_feats, out_feats):\n",
    "        super(GCNLayer, self).__init__()\n",
    "        self.linear = nn.Linear(in_feats, out_feats)\n",
    "\n",
    "    def forward(self, g, feature):\n",
    "        # Creating a local scope so that all the stored ndata and edata\n",
    "        # (such as the `'h'` ndata below) are automatically popped out\n",
    "        # when the scope exits.\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = feature\n",
    "            g.update_all(gcn_msg, gcn_reduce)\n",
    "            h = g.ndata['h']\n",
    "            return self.linear(h)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.layer1 = GCNLayer(1433, 160)\n",
    "        self.layer2 = GCNLayer(160,16)\n",
    "        self.layer3 = GCNLayer(16, 6)\n",
    "    \n",
    "    def forward(self, g, features):\n",
    "        x = F.relu(self.layer1(g, features))\n",
    "        x = F.relu(self.layer2(g, x))\n",
    "        x = self.layer3(g, x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.data import citation_graph as citegrh\n",
    "import networkx as nx\n",
    "\n",
    "def load_cora_data():\n",
    "    data = citegrh.load_cora()\n",
    "    features = th.FloatTensor(data.features)\n",
    "    labels = th.LongTensor(data.labels)\n",
    "    train_mask = th.BoolTensor(data.train_mask)\n",
    "    test_mask = th.BoolTensor(data.test_mask)\n",
    "    g = data.graph\n",
    "    # add self loop\n",
    "    g.remove_edges_from(nx.selfloop_edges(g))\n",
    "    g = dgl.DGLGraph(g)\n",
    "    g.add_edges(g.nodes(), g.nodes())\n",
    "    return g, features, labels, train_mask, test_mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_paper_data():\n",
    "    # pandas reads csv\n",
    "    edges_data = pd.read_csv('data/knowledge_aquisition_reference.csv')\n",
    "    # networkx reads pandas\n",
    "    g_nx: nx.DiGraph = nx.from_pandas_edgelist(edges_data,\n",
    "                                               'paper_id',\n",
    "                                               'reference_id',\n",
    "                                               create_using=nx.DiGraph())\n",
    "\n",
    "    # dgl read networkx\n",
    "    # ATTENTION!!!: nodes in dgl graph is ordered by paperid\n",
    "    g = dgl.from_networkx(g_nx)\n",
    "    features = th.FloatTensor(np.zeros((g.number_of_nodes(), 1433)))\n",
    "    label_pd = pd.read_csv('data/rank_id.csv')\n",
    "    labels = th.LongTensor(label_pd['reference_count'])\n",
    "    train_m = [(labels[i] != 0 and i % 10 <= 1) for i in range(g.number_of_nodes())]\n",
    "    test_m = [(labels[i] != 0 and i % 10 > 1) for i in range(g.number_of_nodes())]\n",
    "    train_mask = th.BoolTensor(train_m)\n",
    "    test_mask = th.BoolTensor(test_m)\n",
    "    return g, features, labels, train_mask, test_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, g, features, labels, mask):\n",
    "    model.eval()\n",
    "    with th.no_grad():\n",
    "        logits = model(g, features)\n",
    "        logits = logits[mask]\n",
    "        labels = labels[mask]\n",
    "        _, indices = th.max(logits, dim=1)\n",
    "        correct = th.sum(indices == labels)\n",
    "        return labels, indices, correct.item() * 1.0 / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "# g, features, labels, train_mask, test_mask = load_cora_data()\n",
    "print('loading graph')\n",
    "g, features, labels, train_mask, test_mask = load_paper_data()\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = th.optim.Adam(net.parameters(), lr=0.04)\n",
    "scheduler = th.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=1)\n",
    "dur = []\n",
    "for epoch in range(100):\n",
    "    t0 = time.time()\n",
    "\n",
    "    net.train()\n",
    "    logits = net(g, features)\n",
    "    logp = F.log_softmax(logits, 1)\n",
    "    loss = F.nll_loss(logp[train_mask], labels[train_mask])\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    dur.append(time.time() - t0)\n",
    "\n",
    "    tmpl,tmpi,acc = evaluate(net, g, features, labels, test_mask)\n",
    "    print(\"Epoch {:05d} | Loss {:.4f} | Test Acc {:.4f} | Time(s) {:.4f}\".format(\n",
    "            epoch, loss.item(), acc, np.mean(dur)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}